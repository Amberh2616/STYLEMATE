import { NextRequest, NextResponse } from 'next/server'
import sharp from 'sharp'
import path from 'path'
import fs from 'fs'

// ğŸ§ª å¯¦é©—æ€§ AI è©¦ç©¿ API
export async function POST(request: NextRequest) {
  try {
    const { userPhotoBase64, productId } = await request.json()
    
    console.log('ğŸš€ é–‹å§‹ AI è©¦ç©¿å¯¦é©—...')
    console.log('ğŸ“· ç”¨æˆ¶ç…§ç‰‡å¤§å°:', userPhotoBase64?.length)
    console.log('ğŸ‘• å•†å“ ID:', productId)
    
    if (!userPhotoBase64 || !productId) {
      return NextResponse.json({
        success: false,
        error: 'éœ€è¦ç”¨æˆ¶ç…§ç‰‡å’Œå•†å“ID'
      }, { status: 400 })
    }
    
    // ğŸ” æ­¥é©Ÿ 1: æ¨¡æ“¬ AI å§¿æ…‹æª¢æ¸¬
    const poseAnalysis = await mockPoseDetection(userPhotoBase64)
    console.log('ğŸ¤– å§¿æ…‹æª¢æ¸¬çµæœ:', poseAnalysis)
    
    // ğŸ“ æ­¥é©Ÿ 2: èº«é«”æ¸¬é‡
    const bodyMeasurements = calculateBodyMeasurements(poseAnalysis)
    console.log('ğŸ“ èº«é«”æ¸¬é‡:', bodyMeasurements)
    
    // ğŸ‘• æ­¥é©Ÿ 3: è¼‰å…¥ä¸¦èª¿æ•´å•†å“
    const productData = await loadAndAdaptProduct(productId, bodyMeasurements)
    console.log('ğŸ‘• å•†å“é©æ‡‰:', productData.adaptations)
    
    // ğŸ¨ æ­¥é©Ÿ 4: æ™ºèƒ½åˆæˆ
    const compositeResult = await experimentalComposite({
      userPhoto: userPhotoBase64,
      adaptedProduct: productData,
      bodyData: bodyMeasurements
    })
    
    return NextResponse.json({
      success: true,
      result: {
        originalPhoto: userPhotoBase64,
        finalResult: compositeResult.base64,
        processingTime: compositeResult.processingTime,
        analysis: {
          pose: poseAnalysis,
          body: bodyMeasurements,
          adaptations: productData.adaptations
        },
        confidence: compositeResult.confidence
      }
    })
    
  } catch (error) {
    console.error('âŒ AI è©¦ç©¿å¯¦é©—å¤±æ•—:', error)
    return NextResponse.json({
      success: false,
      error: error.message,
      stack: process.env.NODE_ENV === 'development' ? error.stack : undefined
    }, { status: 500 })
  }
}

// ğŸ¤– æ¨¡æ“¬å§¿æ…‹æª¢æ¸¬ (å…ˆç”¨ç°¡å–®ç‰ˆæœ¬æ¸¬è©¦)
async function mockPoseDetection(photoBase64: string): Promise<any> {
  // TODO: é€™è£¡å°‡ä¾†æ›¿æ›æˆçœŸæ­£çš„ AI å§¿æ…‹æª¢æ¸¬
  
  // ğŸ“· ç²å–åœ–ç‰‡å°ºå¯¸
  const imageBuffer = Buffer.from(photoBase64.split(',')[1], 'base64')
  const metadata = await sharp(imageBuffer).metadata()
  
  const width = metadata.width || 400
  const height = metadata.height || 600
  
  // ğŸ¯ å‡è¨­æ¨™æº–äººé«”æ¯”ä¾‹ (æ¸¬è©¦ç”¨)
  const mockKeypoints = [
    { name: 'nose', x: width * 0.5, y: height * 0.15, confidence: 0.9 },
    { name: 'left_shoulder', x: width * 0.4, y: height * 0.25, confidence: 0.85 },
    { name: 'right_shoulder', x: width * 0.6, y: height * 0.25, confidence: 0.87 },
    { name: 'left_elbow', x: width * 0.35, y: height * 0.4, confidence: 0.8 },
    { name: 'right_elbow', x: width * 0.65, y: height * 0.4, confidence: 0.82 },
    { name: 'left_hip', x: width * 0.45, y: height * 0.6, confidence: 0.75 },
    { name: 'right_hip', x: width * 0.55, y: height * 0.6, confidence: 0.78 }
  ]
  
  return {
    keypoints: mockKeypoints,
    imageSize: { width, height },
    confidence: 0.83,
    detectionTime: Math.random() * 1000 + 500 // 0.5-1.5ç§’
  }
}

// ğŸ“ è¨ˆç®—èº«é«”æ¸¬é‡
function calculateBodyMeasurements(poseData: any) {
  const { keypoints, imageSize } = poseData
  
  const leftShoulder = keypoints.find((p: any) => p.name === 'left_shoulder')
  const rightShoulder = keypoints.find((p: any) => p.name === 'right_shoulder')
  const leftHip = keypoints.find((p: any) => p.name === 'left_hip')
  const rightHip = keypoints.find((p: any) => p.name === 'right_hip')
  
  // ğŸ“Š è¨ˆç®—é—œéµæ¸¬é‡
  const shoulderWidth = Math.abs(rightShoulder.x - leftShoulder.x)
  const hipWidth = Math.abs(rightHip.x - leftHip.x)
  const torsoHeight = Math.abs((leftHip.y + rightHip.y) / 2 - (leftShoulder.y + rightShoulder.y) / 2)
  
  const shoulderCenter = {
    x: (leftShoulder.x + rightShoulder.x) / 2,
    y: (leftShoulder.y + rightShoulder.y) / 2
  }
  
  return {
    shoulderWidth,
    hipWidth,
    torsoHeight,
    shoulderCenter,
    bodyRatio: shoulderWidth / hipWidth,
    imageSize,
    confidence: 0.85
  }
}

// ğŸ‘• è¼‰å…¥å’Œé©æ‡‰å•†å“
async function loadAndAdaptProduct(productId: string, bodyData: any) {
  const productPath = path.join(process.cwd(), 'public', 'images', 'products', `${productId}.jpg`)
  
  if (!fs.existsSync(productPath)) {
    throw new Error(`å•†å“åœ–ç‰‡ä¸å­˜åœ¨: ${productId}`)
  }
  
  // ğŸ“ æ ¹æ“šèº«é«”æ¸¬é‡èª¿æ•´è¡£æœ
  const clothingScale = Math.max(0.8, Math.min(1.5, bodyData.shoulderWidth / 150)) // å‡è¨­æ¨™æº–è‚©å¯¬ 150px
  
  const adaptations = {
    scale: clothingScale,
    position: {
      x: bodyData.shoulderCenter.x,
      y: bodyData.shoulderCenter.y,
    },
    rotation: 0, // æš«æ™‚ä¸æ—‹è½‰
    opacity: 0.9
  }
  
  return {
    productPath,
    adaptations,
    originalSize: await sharp(productPath).metadata()
  }
}

// ğŸ¨ å¯¦é©—æ€§åˆæˆ
async function experimentalComposite(params: any) {
  const startTime = Date.now()
  
  try {
    const { userPhoto, adaptedProduct, bodyData } = params
    
    // ğŸ“· è™•ç†ç”¨æˆ¶ç…§ç‰‡
    const userPhotoBuffer = Buffer.from(userPhoto.split(',')[1], 'base64')
    const userImage = sharp(userPhotoBuffer)
    
    // ğŸ‘• è™•ç†å•†å“åœ–ç‰‡
    const productImage = sharp(adaptedProduct.productPath)
    
    // ğŸ”§ èª¿æ•´å•†å“å°ºå¯¸å’Œä½ç½® - ä¿®æ­£ç‰ˆæœ¬
    // ä¿®æ­£ï¼šè¡£æœæ‡‰è©²æ˜¯åˆç†çš„å°ºå¯¸ï¼Œä¸æ˜¯æ•´å¼µç…§ç‰‡çš„å°ºå¯¸
    const targetWidth = Math.round(bodyData.shoulderWidth * 1.2) // æ¯”è‚©è†€ç¨å¾®å¯¬ä¸€é»
    const targetHeight = Math.round(targetWidth * 1.3) // ä¸Šè¡£çš„åˆç†é«˜å¯¬æ¯”
    
    console.log('ğŸ”§ è¡£æœèª¿æ•´ï¼š', `${targetWidth}x${targetHeight}`)
    
    const scaledProduct = await productImage
      .resize({
        width: targetWidth,
        height: targetHeight,
        fit: 'cover', // æ”¹ç‚º coverï¼Œè®“è¡£æœå¡«æ»¿æ¡†æ¶
        background: { r: 255, g: 255, b: 255, alpha: 0.8 } // åŠé€æ˜ç™½è‰²èƒŒæ™¯
      })
      .png({ 
        quality: 90,
        compressionLevel: 6,
        force: true
      })
      .toBuffer()
    
    // ğŸ¨ åˆæˆåœ–ç‰‡ - ä¿®æ­£ç‰ˆæœ¬
    const clothingWidth = targetWidth  // ä½¿ç”¨æ–°çš„æ­£ç¢ºå°ºå¯¸
    const clothingHeight = targetHeight
    
    // è¨ˆç®—æ›´æº–ç¢ºçš„ä½ç½® - è¡£æœä¸­å¿ƒå°é½Šè‚©è†€ä¸­å¿ƒ
    const leftPosition = Math.round(adaptedProduct.adaptations.position.x - clothingWidth / 2)
    const topPosition = Math.round(adaptedProduct.adaptations.position.y - clothingHeight / 4) // è¡£æœç¨å¾®å¾€ä¸Š
    
    console.log('ğŸ¨ åˆæˆåƒæ•¸:')
    console.log('  è¡£æœå°ºå¯¸:', clothingWidth, 'x', clothingHeight)
    console.log('  æ”¾ç½®ä½ç½®:', leftPosition, ',', topPosition)
    console.log('  è‚©è†€ä¸­å¿ƒ:', adaptedProduct.adaptations.position)
    
    const compositeResult = await userImage
      .composite([{
        input: scaledProduct,
        left: leftPosition,
        top: topPosition,
        blend: 'multiply'  // æ”¹ç”¨ multiply æ¨¡å¼ï¼Œè®“è¡£æœæ›´è‡ªç„¶èåˆ
      }])
      .png({ 
        quality: 95,
        compressionLevel: 6,
        force: true
      })
      .toBuffer()
    
    const processingTime = Date.now() - startTime
    
    return {
      base64: `data:image/png;base64,${compositeResult.toString('base64')}`,
      processingTime,
      confidence: 0.8
    }
    
  } catch (error) {
    console.error('åˆæˆéŒ¯èª¤:', error)
    throw new Error(`åœ–ç‰‡åˆæˆå¤±æ•—: ${error.message}`)
  }
}