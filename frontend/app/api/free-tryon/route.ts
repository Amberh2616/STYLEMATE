import { NextRequest, NextResponse } from 'next/server'

// å…è²»çš„è™›æ“¬è©¦ç©¿ API - ä½¿ç”¨ Hugging Face Spaces
export async function POST(request: NextRequest) {
  try {
    const { userPhotoBase64, clothingImageBase64 } = await request.json()

    console.log('ğŸ†“ é–‹å§‹å…è²» AI è©¦ç©¿...')

    if (!userPhotoBase64 || !clothingImageBase64) {
      return NextResponse.json({
        success: false,
        error: 'éœ€è¦äººç‰©ç…§ç‰‡å’Œæœè£åœ–ç‰‡'
      }, { status: 400 })
    }

    // ä½¿ç”¨å…è²»çš„ Hugging Face Gradio API
    try {
      console.log('ğŸ“¤ èª¿ç”¨å…è²» Gradio API...')
      
      // é€™æ˜¯ä¸€å€‹æ¨¡æ“¬çš„å›æ‡‰ï¼Œå› ç‚ºçœŸæ­£çš„ Gradio èª¿ç”¨éœ€è¦ç‰¹æ®Šè™•ç†
      // æ‚¨ä¹Ÿå¯ä»¥æ‰‹å‹•åˆ° https://huggingface.co/spaces/yisol/IDM-VTON æ¸¬è©¦
      
      const simulatedResult = await createSimulatedResult(userPhotoBase64, clothingImageBase64)
      
      return NextResponse.json({
        success: true,
        result: {
          originalPhoto: userPhotoBase64,
          finalResult: simulatedResult,
          processingTime: 3000,
          model: 'å…è²»é«”é©—ç‰ˆ',
          analysis: {
            method: 'gradio_simulation',
            message: 'å¦‚éœ€çœŸæ­£çš„ AI è©¦ç©¿ï¼Œè«‹ä½¿ç”¨ä»˜è²» Replicate æœå‹™'
          }
        }
      })

    } catch (error) {
      throw new Error(`å…è²»æœå‹™æš«æ™‚ä¸å¯ç”¨: ${error.message}`)
    }

  } catch (error) {
    console.error('âŒ å…è²»è©¦ç©¿å¤±æ•—:', error)
    return NextResponse.json({
      success: false,
      error: error.message,
      suggestion: 'å»ºè­°ä½¿ç”¨ä»˜è²» Replicate æœå‹™ç²å¾—æœ€ä½³æ•ˆæœ'
    }, { status: 500 })
  }
}

// å‰µå»ºæ”¹é€²ç‰ˆçš„æ¨¡æ“¬çµæœ
async function createSimulatedResult(personBase64: string, clothingBase64: string) {
  const sharp = require('sharp')
  
  try {
    // è™•ç†åœ–ç‰‡
    const personBuffer = Buffer.from(personBase64.split(',')[1], 'base64')
    const clothingBuffer = Buffer.from(clothingBase64.split(',')[1], 'base64')
    
    const personImage = sharp(personBuffer)
    const { width, height } = await personImage.metadata()
    
    // æ”¹é€²çš„åˆæˆç®—æ³•
    const processedClothing = await sharp(clothingBuffer)
      .resize({
        width: Math.round((width || 400) * 0.45),
        height: Math.round((height || 600) * 0.35),
        fit: 'contain',
        background: { r: 0, g: 0, b: 0, alpha: 0 }
      })
      .modulate({
        brightness: 0.9,
        saturation: 1.05
      })
      .png()
      .toBuffer()

    // æ›´æ™ºèƒ½çš„å®šä½
    const composite = await personImage
      .composite([{
        input: processedClothing,
        left: Math.round((width || 400) * 0.275),
        top: Math.round((height || 600) * 0.25),
        blend: 'over'
      }])
      .png()
      .toBuffer()

    return `data:image/png;base64,${composite.toString('base64')}`

  } catch (error) {
    throw new Error('åœ–ç‰‡è™•ç†å¤±æ•—')
  }
}